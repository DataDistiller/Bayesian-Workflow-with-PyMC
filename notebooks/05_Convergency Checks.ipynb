{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convergency checks\n",
    "In this model, we use ArviZ to check if our model has converged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src/')\n",
    "\n",
    "import pymc3 as pm\n",
    "import arviz as az\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from utils.data_utils import load_data\n",
    "from utils.plot_utils import set_plot_defaults\n",
    "from utils.convergence_utils import check_mcse, check_neff, check_rhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_plot_defaults(font=\"Europace Sans\")\n",
    "plt.rcParams['font.size'] = 16\n",
    "plt.rcParams['axes.titlesize'] = 20\n",
    "d, zip_lookup, num_zip_codes = load_data(kind=\"prices\")   # loads data from data/interim_data/houses.csv \n",
    "                                                          # aternatively, use kind=\"rents\" to load data from data/interim_data/rent.csv\n",
    "zip_codes = np.sort(d.zip.unique())\n",
    "target = \"price_s\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will check both the centered hierarchical model as well as the bad model, just to see how a model looks like that did not converge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = az.from_netcdf(\"../models/centered_hier.nc\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_data = az.from_netcdf(\"../models/bad_model.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(data.posterior)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trace plots\n",
    "The first thing to check to see if a model converged or not are the trace plots. If you have more than 2 chains, it can be a good idea to only look at two, otherwise the plots can get very crowded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(data, var_names=[\"mu_alpha\", \"mu_beta\", \"sigma_alpha\", \"sigma_beta\"],\n",
    "             coords={\"chain\":[0,1]})\n",
    "plt.suptitle(\"Trace plots\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These trace plots look goot but we only look here at a selection of parameters. Remember that for each ZIP code, we fit both an $\\alpha$ and $\\beta$ parameter.\n",
    "This means we actually have hundreds of parameter and we cannot feasibly plot all of them and look at all of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rhat statistic\n",
    "The Rhat statistic measures how similar the different chains are. So to be able to compute it, we need at least two chains. If all chains converged to the same distribution, then the Rhat statistic should be close to 1.\n",
    "An Rhat greater than 1.1 means something is very wrong and your model did not converge (in this case, PyMC3 will also raise some warnings). However, already a value above 1.01 is reason for concern, so when computing it via the summary function from ArviZ, it is best to deactive rounding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = az.summary(data, round_to=\"none\")\n",
    "s.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I built a small convenience function that plots a histogram of the Rhat over all parameters and also tells you which parameters (if any) are above a certain threshold. This way, we can then analyse these parameters further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_rhat(data, threshold=1.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_rhat(data, threshold=1.005)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(data, var_names=[\"alpha\", 'beta'], \n",
    "              coords={\"zip_code\": [zip_codes[205], zip_codes[191]]})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare this with the bad model, a huge bunch of parameters have a very Rhat! Not very good!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_rhat(bad_data, threshold=1.01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of effective samples\n",
    "Since the samples coming from one chain are usually autocorrelated. This means, the posterior sample we get is not an independent sample of the posterior distribution. The ESS, Effective sample size, estimates how many independent draws we roughly have in our sample. \n",
    "If the number of effective samples is very low (e.g. less than 10%) compared to the number of iterations (size of the posterior sample), then there might be a problem with our model. \n",
    "\n",
    "Note that it depends on your use case how many effective samples you need. If you only want to estimate the mean and median of the posterior distribution, then ~300 effective samples can be enough. If however you want to estimate very high or low percentiles, you will need much more.\n",
    "\n",
    "For a bit more about the maths behind it, check this [section](https://mc-stan.org/docs/2_20/reference-manual/effective-sample-size-section.html).\n",
    "\n",
    "I build a similr convenience function for the ESS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_neff(data, threshold=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monte Carlo Standard Error\n",
    "The Monte Carlo standard error is given by the posterior standard deviation divided by the square root of the number of effective samples. The smaller the standard error, the closer the posterior mean is expected to be to the true value. This standard error should not be greater than 10% of the posterior standard deviation.\n",
    "For more details, check e.g. the [Stan user manual](https://mc-stan.org/docs/2_18/reference-manual/effective-sample-size-section.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_mcse(data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some bad examples\n",
    "In the next section, I fit a few models that have not converged, just to show how this looks like in the convergence diagnostics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data of the Eight Schools Model\n",
    "J = 8\n",
    "y = np.array([28.,  8., -3.,  7., -1.,  1., 18., 12.])\n",
    "sigma = np.array([15., 10., 16., 11.,  9., 11., 10., 18.])\n",
    "# tau = 25.\n",
    "with pm.Model() as Centered_eight:\n",
    "    mu = pm.Normal('mu', mu=0, sigma=5)\n",
    "    tau = pm.HalfCauchy('tau', beta=5)\n",
    "    theta = pm.Normal('theta', mu=mu, sigma=tau, shape=J)\n",
    "    obs = pm.Normal('obs', mu=theta, sigma=sigma, observed=y)\n",
    "    posterior = pm.sample(tune=50, draws=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model has only been tuned for a very short time and this leads to various convergence problems. PyMC itself warns us that the Rhat (here called Gelman-Rubin statistic) is large and that the number of effective samples is very small. Also there were quite many divergences.\n",
    "\n",
    "We also see this in the trace plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(posterior, var_names=[\"mu\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing the tuning steps leads to less divergences and less warnings, but there are still many problems with this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data of the Eight Schools Model\n",
    "J = 8\n",
    "y = np.array([28.,  8., -3.,  7., -1.,  1., 18., 12.])\n",
    "sigma = np.array([15., 10., 16., 11.,  9., 11., 10., 18.])\n",
    "# tau = 25.\n",
    "with pm.Model() as Centered_eight:\n",
    "    mu = pm.Normal('mu', mu=0, sigma=5)\n",
    "    tau = pm.HalfCauchy('tau', beta=5)\n",
    "    theta = pm.Normal('theta', mu=mu, sigma=tau, shape=J)\n",
    "    obs = pm.Normal('obs', mu=theta, sigma=sigma, observed=y)\n",
    "    posterior = pm.sample(tune=500, draws=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(posterior, var_names=[\"mu\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see in the trace plots that the chains did not explore the posterior space well and that there is high autocorrelation. We can plot the autocorrelation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes = az.plot_autocorr(posterior, var_names=[\"mu\"], figsize=(13,6))\n",
    "for axe in axes:\n",
    "    for ax in axe:\n",
    "        ax.spines[\"top\"].set_visible(False)  \n",
    "        ax.spines[\"right\"].set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For comparison, a model with low autocorrelation looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes = az.plot_autocorr(data, var_names=[\"mu_alpha\"], figsize=(13,6))\n",
    "for axe in axes:\n",
    "    for ax in axe:\n",
    "        ax.spines[\"top\"].set_visible(False)  \n",
    "        ax.spines[\"right\"].set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model above is the classic example of where a centered parametrization is problematic. \n",
    "We thus try a non-centered parametrization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as NonCentered_eight:\n",
    "    mu = pm.Normal('mu', mu=0, sigma=5)\n",
    "    tau = pm.HalfCauchy('tau', beta=5)\n",
    "    theta_tilde = pm.Normal('theta_t', mu=0, sigma=1, shape=J)\n",
    "    theta = pm.Deterministic('theta', mu + tau * theta_tilde)\n",
    "    obs = pm.Normal('obs', mu=theta, sigma=sigma, observed=y)\n",
    "    posterior = pm.sample(target_accept=0.9, draws=500, tune=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(posterior, var_names=[\"mu\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the trace plot looks much better.\n",
    "\n",
    "The trace plots for the bad model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(bad_data, var_names=['alpha', \"beta\"], coords={\"zip_code\": [zip_codes[54]],\n",
    "                                                    \"chain\": [0,1]})\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda3-2019.03",
   "language": "python",
   "name": "anaconda3-2019.03"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
